#!/bin/bash

function	scrap_website()
{
	local	url="${1%%,*}"
	local	pre="${PACKAGE_PREFIX[${2}]}"
	local	suf="${PACKAGE_SUFFIX[${2}]}"
	local	reg="${SED_LATEST} ${SED_HREF_BEG}${pre}.*${suf}${SED_HREF_END}"
	local	out=($(curl ${CURL_OPT} ${url} | sed -n "${reg}"))
	local	mode=${3:-}

	if [ "${#out[@]}" != "0" ]; then
		if [ "${url: -8}" == "?C=M&O=D" ]; then
			echo "${out[0]}"
		elif [ "${mode}" != "" ]; then
			case "${mode}" in
				"fossies_search")
					echo "https://fossies.org${out[0]}"
					;;
				"fossies")
					echo "${url%/*}${out[0]}"
					;;
			esac
		else
			case "${2}" in
				"iproute2")
					echo "https://git.kernel.org${out[0]}"
					;;
				"less")
					echo "https://www.greenwoodsoftware.com/less/${out[0]}"
					;;
				"intltool"|"python"|"tcl"|"xml-parser")
					echo "${out[0]}"
					;;
				"python-doc"|"tcl-doc")
					echo "${url%/*}/${out[0]}"
				;;
				*)
					echo "${1}/${out[0]}"
					;;
			esac
		fi
	fi
}

function	scrap_fossies()
{
	scrap_website "${1}" "${2}" "fossies"
}

function	scrap_fossies_search()
{
	scrap_website "${1}" "${2}" "fossies_search"
}

function	scrap_apache()
{
	local	scrap_res="$(scrap_website "${1}/?C=M&O=D" "${2}")"

	if [ "${scrap_res}" != "" ]; then
		case "${2}" in
			"perl")
				echo "${scrap_res}"
				;;
			*)
				echo "${1}/${scrap_res}"
				;;
		esac
	fi
}

function	scrap_apache_dir()
{
	local	url="${1}/?C=M&O=D"
	local	pre="${PACKAGE_PREFIX[${2}]}"
	local	suf="${PACKAGE_SUFFIX[${2}]}"
	local	out=($( \
		curl ${CURL_OPT} ${url} \
		| sed -n "${SED_LATEST} ${SED_HREF_BEG}/${SED_HREF_END}" \
	))

	if [ "${#out[@]}" != "0" ]; then
		scrap_apache "${1}/${out[1]%/}" "${2}"
	fi
}

function	scrap_github()
{
	local	pre="${PACKAGE_PREFIX[${2}]}"
	local	suf="${PACKAGE_SUFFIX[${2}]}"
	local	out=($( \
		curl ${CURL_OPT} -H "Authorization: Bearer ${GITHUB_PAT}" https://api.github.com/repos/${1}/releases/latest \
		| sed -n "${SED_LATEST} s/.*\"\(https.*${pre}.*${suf}\)\"$/\1/p" \
	))

	if [ "${#out[@]}" != "0" ]; then
		echo "${out[0]}"
	fi
}

function	scrap_github_tag()
{
	local	pre="${PACKAGE_PREFIX[${2}]}"
	local	suf="${PACKAGE_SUFFIX[${2}]}"
	local	out="$(curl ${CURL_OPT} https://github.com/${1}/tags \
		| grep -m1 -Eo "archive/refs/tags/[^/]+\.tar\.gz")"

	if [ "${#out}" != "0" ]; then
		echo "https://github.com/${1}/${out}"
	fi
}

function	scrap_gitlab()
{
	local	pre="${PACKAGE_PREFIX[${2}]}"
	local	suf="${PACKAGE_SUFFIX[${2}]}"
	local	out=$( \
		curl ${CURL_OPT} -X POST https://gitlab.com/api/graphql  \
			-H "Content-Type: application/json" \
			-d '{
				"operationName":"allReleases",
				"variables": {
					"fullPath":"'${1}'",
					"first":1,
					"sort":"RELEASED_AT_DESC"
				},
				"query":"query allReleases($fullPath:ID!,$first:Int,$last:Int,$before:String,$after:String,$sort:ReleaseSort){project(fullPath:$fullPath) {releases(first:$first last:$last before:$before after:$after sort:$sort){nodes{...Release}}}}fragment Release on Release{assets{sources{ nodes{url}}}}"
			}'\
			| sed -n "${SED_LATEST} s|.*\"url\":\"\(https.*${pre}.*.${suf}\)\".*|\1|p"
	)
	echo "${out}"
}

function	scrap_pypi()
{
	local	url="https://pypi.org/project/${1}/#files"
	local	pre="${PACKAGE_PREFIX[${2}]}"
	local	suf="${PACKAGE_SUFFIX[${2}]}"
	local	out=$(curl ${CURL_OPT} ${url} \
		| sed -n "${SED_LATEST} ${SED_HREF_BEG}https://.*${pre}.*${suf}${SED_HREF_END}")

	if [ "${#out}" != "0" ]; then
		echo "${out[0]}"
	fi
}

function	scrap_no_scrap()
{ echo "${1}"; }

function	scrap()
{
	local	pack_type="${PACKAGE_REPO[${1}]%%,*}"
	local	pack_url="${PACKAGE_REPO[${1}]#*,}"

	if declare -f "scrap_${pack_type}" > /dev/null; then
		"scrap_${pack_type}" "${pack_url}" "${1}"
	else
		echo "UNKNOWN_FUNC"
	fi
}
