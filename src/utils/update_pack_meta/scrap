#!/usr/bin/bash

function	scrap_website()
{
	local	url="${1%%,*}"
	local	pre="${PACKAGE_PREFIX[${2}]}"
	local	suf="${PACKAGE_SUFFIX[${2}]}"
	local	reg="${SED_LATEST} ${SED_HREF_BEG}${pre}.*${suf}${SED_HREF_END}"

	# CURL_OPT need to be expanded as unique words
	# shellcheck disable=SC2086
	# No quote to get all avalaible links
	# shellcheck disable=SC2207
	local	out=($(curl ${CURL_OPT} "${url}" | sed -n "${reg}"))
	local	mode="${3:-}"

	if [ "${#out[@]}" != "0" ]; then
		if [ "${url: -8}" == "?C=M&O=D" ]; then
			echo "${out[0]}"
		elif [ "${mode}" != "" ]; then
			case "${mode}" in
				"fossies_search")
					echo "https://fossies.org${out[0]}"
					;;
				"fossies")
					echo "${url%/*}/${out[0]##*/}"
					;;
				"sourceforge")
					echo "${out[0]%\/download*}"
					;;
				*)
					echo "UNKNOWN_MODE"
					;;
			esac
		else
			case "${2}" in
				"iproute2")
					echo "https://git.kernel.org${out[0]}"
					;;
				"less")
					echo "https://www.greenwoodsoftware.com/less/${out[0]}"
					;;
				"intltool"|"python"|"tcl"|"xml-parser"|"linux"|"pkgconf")
					echo "${out[0]}"
					;;
				"python-doc"|"tcl-doc")
					echo "${url%/*}/${out[0]}"
				;;
				*)
					echo "${1}/${out[0]}"
					;;
			esac
		fi
	fi
}

function	scrap_fossies()
{
	scrap_website "${1}" "${2}" "fossies"
}

function	scrap_fossies_search()
{
	scrap_website "${1}" "${2}" "fossies_search"
}

function	scrap_sourceforge()
{
	scrap_website "${1}" "${2}"	"sourceforge"
}

function	scrap_apache()
{
	local	scrap_res
	scrap_res="$(scrap_website "${1}/?C=M&O=D" "${2}")"

	if [ "${scrap_res}" != "" ]; then
		case "${2}" in
			"perl")
				echo "${scrap_res}"
				;;
			*)
				echo "${1}/${scrap_res}"
				;;
		esac
	fi
}

function	scrap_apache_dir()
{
	local	url="${1}/?C=M&O=D"
	local	pre="${PACKAGE_PREFIX[${2}]}"
	local	suf="${PACKAGE_SUFFIX[${2}]}"
	# CURL_OPT need to be expanded as unique words
	# shellcheck disable=SC2086
	# No quote to get all avalaible links
	# shellcheck disable=SC2207
	local	out=($(curl ${CURL_OPT} "${url}" \
		| sed -n "${SED_LATEST} ${SED_HREF_BEG}/${SED_HREF_END}"))

	if [ "${#out[@]}" != "0" ]; then
		scrap_apache "${1}/${out[1]%/}" "${2}"
	fi
}

function	scrap_apache_no_sort()
{
	declare -A TMP_FILE
	local	n="[0-9]"
	local	a="[a-zA-Z]"
	local	r="${n}\{2\}-${a}\{3\}-${n}\{4\} ${n}\{2\}:${n}\{2\}"
	local	p="${PACKAGE_PREFIX[${2}]}"
	local	s="${PACKAGE_SUFFIX[${2}]}"

	# CURL_OPT need to be expanded as unique words
	# shellcheck disable=SC2086
	while read -r line; do
		file=$(sed -n "${SED_LATEST} ${SED_HREF_BEG}${p}.*${s}${SED_HREF_END}" <<<"${line}" )
		[ ${#file} == 0 ] && continue
		date=$(sed -n "s|.*${file}.*\(${r}\).*|\1|p" <<<"${line}")
		date=$(date -d "${date}" +"%s")
		TMP_FILE[${date}]="${file}"
	done < <(curl ${CURL_OPT} "${1}")

	# No quote to to split on IFS
	# shellcheck disable=SC2207
	ORDER=($(echo "${!TMP_FILE[@]}" | tr ' ' '\n' | sort -rn))

	echo "${1}/${TMP_FILE[${ORDER[0]}]}"

	unset TMP_FILE ORDER
}

SED_PARENT_DIR="/.*\.\.\/.*/!"

function	scrap_apache_no_sort_dir()
{
	declare -A TMP_FILE
	local	n="[0-9]"
	local	a="[a-zA-Z]"
	local	r="${n}\{2\}-${a}\{3\}-${n}\{4\} ${n}\{2\}:${n}\{2\}"
	local	p="${PACKAGE_PREFIX[${2}]}"
	local	s="${PACKAGE_SUFFIX[${2}]}"

	# CURL_OPT need to be expanded as unique words
	# shellcheck disable=SC2086
	while read -r line; do
		file=$(sed -n "${SED_PARENT_DIR} ${SED_HREF_BEG}.*${SED_HREF_END}" <<<"${line}" )
		[ ${#file} == 0 ] && continue
		date=$(sed -n "s|.*${file}.*\(${r}\).*|\1|p" <<<"${line}")
		date=$(date -d "${date}" +"%s")
		TMP_FILE[${date}]="${file}"
	done < <(curl ${CURL_OPT} "${1}")

	# No quote to get all avalaible links
	# shellcheck disable=SC2207
	local	order=($(echo "${!TMP_FILE[@]}" | tr ' ' '\n' | sort -rn))

	# get an item even if order is empty
	for item in "${order[@]}"; do
		res1="${item}"
		break
	done

	if [ "${res1}" != "" ]; then
		res1="${TMP_FILE[${res1}]}"
		res2="${res1%/}"
		res2="${res2#v}"
		echo "${1}/${res1}${p}${res2%/}${s}"
	fi
}

function	scrap_github()
{
	local	pre="${PACKAGE_PREFIX[${2}]}"
	local	suf="${PACKAGE_SUFFIX[${2}]}"
	# CURL_OPT need to be expanded as unique words
	# shellcheck disable=SC2086
	# No quote to get all avalaible links
	# shellcheck disable=SC2207
	local	out=($(curl ${CURL_OPT} -H "Authorization: Bearer ${GITHUB_PAT}" \
			"https://api.github.com/repos/${1}/releases/latest" \
		| sed -n "${SED_LATEST} s/.*\"\(https.*${pre}.*${suf}\)\"$/\1/p"))

	if [ "${#out[@]}" != "0" ]; then
		echo "${out[0]}"
	fi
}

function	scrap_github_tag()
{
	local	pre="${PACKAGE_PREFIX[${2}]}"
	local	suf="${PACKAGE_SUFFIX[${2}]}"
	local	out
	# CURL_OPT need to be expanded as unique words
	# shellcheck disable=SC2086
	out="$(curl ${CURL_OPT} "https://github.com/${1}/tags" \
		| grep -m1 -Eo "archive/refs/tags/[^/]+\.tar\.gz")"

	if [ "${#out}" != "0" ]; then
		echo "https://github.com/${1}/${out}"
	fi
}

function	scrap_gitlab()
{
	local	pre="${PACKAGE_PREFIX[${2}]}"
	local	suf="${PACKAGE_SUFFIX[${2}]}"
	local	out
	# CURL_OPT need to be expanded as unique words
	# shellcheck disable=SC2086
	# GraphQL query to get the latest release
	# shellcheck disable=SC2016
	out=$(curl ${CURL_OPT} -X POST https://gitlab.com/api/graphql  \
			-H "Content-Type: application/json" \
			-d '{
				"operationName":"allReleases",
				"variables": {
					"fullPath":"'"${1}"'",
					"first":1,
					"sort":"RELEASED_AT_DESC"
				},
				"query":"query allReleases($fullPath:ID!,$first:Int,$last:Int,$before:String,$after:String,$sort:ReleaseSort){project(fullPath:$fullPath) {releases(first:$first last:$last before:$before after:$after sort:$sort){nodes{...Release}}}}fragment Release on Release{assets{sources{ nodes{url}}}}"
			}'\
			| sed -n "${SED_LATEST} s|.*\"url\":\"\(https.*${pre}.*.${suf}\)\".*|\1|p"
	)
	echo "${out}"
}

function	scrap_pypi()
{
	local	url="https://pypi.org/project/${1}/#files"
	local	pre="${PACKAGE_PREFIX[${2}]}"
	local	suf="${PACKAGE_SUFFIX[${2}]}"
	local	out
	# CURL_OPT need to be expanded as unique words
	# shellcheck disable=SC2086
	out=$(curl ${CURL_OPT} "${url}" \
		| sed -n "${SED_LATEST} ${SED_HREF_BEG}https://.*${pre}.*${suf}${SED_HREF_END}")

	if [ "${#out}" != "0" ]; then
		echo "${out[0]}"
	fi
}

function	scrap_no_scrap()
{ echo "${1}"; }

function	scrap()
{
	local	pack_type="${PACKAGE_REPO[${1}]%%,*}"
	local	pack_url="${PACKAGE_REPO[${1}]#*,}"

	if declare -f "scrap_${pack_type}" > /dev/null; then
		"scrap_${pack_type}" "${pack_url}" "${1}"
	else
		echo "UNKNOWN_FUNC"
	fi
}
